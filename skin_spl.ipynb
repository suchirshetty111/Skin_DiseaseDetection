{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWfKxYiMa0pM"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d shubhamgoel27/dermnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HPMAucZa__p",
        "outputId": "ac1a0afb-ff1c-4f9a-f039-318e29307885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading dermnet.zip to /content\n",
            " 99% 1.71G/1.72G [00:09<00:00, 230MB/s]\n",
            "100% 1.72G/1.72G [00:09<00:00, 192MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dermnet.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "e48IdS0ybCAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ConvNeXtTiny\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# === CONFIG ===\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 7\n",
        "NUM_CLASSES = 23  # Adjust if needed\n",
        "\n",
        "# === LOAD DATA ===\n",
        "train_ds = image_dataset_from_directory(\n",
        "    \"/content/train\",\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    \"/content/test\",\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# === DATA AUGMENTATION ===\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# === PREFETCH ===\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# === BASE MODEL ===\n",
        "base_model = ConvNeXtTiny(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    weights=\"imagenet\",\n",
        "    pooling=None\n",
        ")\n",
        "base_model.trainable = True  # Fine-tune\n",
        "\n",
        "# === MODEL BUILD ===\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=True)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# === COMPILE ===\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# === CALLBACKS ===\n",
        "early_stop = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"best_convnext_model.keras\", save_best_only=True)\n",
        "\n",
        "# === TRAIN ===\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDdySsVTcHN0",
        "outputId": "b6ade945-b256-464a-bbf5-c32baa41e484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15557 files belonging to 23 classes.\n",
            "Found 4002 files belonging to 23 classes.\n",
            "Epoch 1/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 1s/step - accuracy: 0.1755 - loss: 3.4419 - val_accuracy: 0.3488 - val_loss: 2.3510\n",
            "Epoch 2/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 1s/step - accuracy: 0.3614 - loss: 2.3339 - val_accuracy: 0.4133 - val_loss: 2.0514\n",
            "Epoch 3/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 1s/step - accuracy: 0.4664 - loss: 1.8634 - val_accuracy: 0.4635 - val_loss: 1.9026\n",
            "Epoch 4/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 1s/step - accuracy: 0.5511 - loss: 1.5196 - val_accuracy: 0.5217 - val_loss: 1.6829\n",
            "Epoch 5/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 1s/step - accuracy: 0.6458 - loss: 1.1968 - val_accuracy: 0.5537 - val_loss: 1.5976\n",
            "Epoch 6/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 1s/step - accuracy: 0.7076 - loss: 0.9634 - val_accuracy: 0.5572 - val_loss: 1.6731\n",
            "Epoch 7/7\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 1s/step - accuracy: 0.7677 - loss: 0.7460 - val_accuracy: 0.5920 - val_loss: 1.5697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"convnext_tiny_trained.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS1xO8P3f1bn",
        "outputId": "7482af39-a1f0-4fa9-8637-216cfd5e112b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "0Ct-WlOPtq6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}